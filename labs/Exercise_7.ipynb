{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_7_Minibatch_P3.ipynb.txt",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziZ9i7tXbO1T"
      },
      "source": [
        "In this lab, you should try to implement some of the techniques discussed in the lecture.\n",
        "Here is a list of reasonable tasks.\n",
        " \n",
        "Easy:\n",
        " * L1 or L2 regularization (choose one)\n",
        " * momentum, Nesterov's momentum (choose one)\n",
        "\n",
        "Medium difficulty:\n",
        " * Adagrad, RMSProp (choose one)\n",
        " * dropout\n",
        " * data augmentation (tiny rotatations, up/down-scalings etc.)\n",
        "\n",
        "Try to test your network to see if these changes improve accuracy. They improve accuracy much more if you increase the layer size, and if you add more layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P22HqX9AbO1a"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from scipy.ndimage.interpolation import rotate\n",
        "from scipy.ndimage import shift, zoom\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9jGPaZhbO2B"
      },
      "source": [
        "# Let's read the mnist dataset\n",
        "\n",
        "def load_mnist(path='.'):\n",
        "    train_set = datasets.MNIST(path, train=True, download=True)\n",
        "    x_train = train_set.data.numpy()\n",
        "    _y_train = train_set.targets.numpy()\n",
        "    \n",
        "    test_set = datasets.MNIST(path, train=False, download=True)\n",
        "    x_test = test_set.data.numpy()\n",
        "    _y_test = test_set.targets.numpy()\n",
        "    \n",
        "    x_train = x_train.reshape((x_train.shape[0],28*28)) / 255.\n",
        "    x_test = x_test.reshape((x_test.shape[0],28*28)) / 255.\n",
        "\n",
        "    y_train = np.zeros((_y_train.shape[0], 10))\n",
        "    y_train[np.arange(_y_train.shape[0]), _y_train] = 1\n",
        "    \n",
        "    y_test = np.zeros((_y_test.shape[0], 10))\n",
        "    y_test[np.arange(_y_test.shape[0]), _y_test] = 1\n",
        "\n",
        "    x_validation = x_train[:10000]\n",
        "    y_validation = y_train[:10000]\n",
        "\n",
        "    return (x_train[10000:], y_train[10000:]), (x_test, y_test), (x_validation, y_validation)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test), (x_validation, y_validation) = load_mnist()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXak83vUeMR6"
      },
      "source": [
        "class Augmenter:\n",
        "    rotation: int\n",
        "    horizontal_shift: int\n",
        "    vertical_shift: int\n",
        "\n",
        "    def __init__(self, rotation: int = 10, horizontal_shift: int = 4, vertical_shift: int = 2):\n",
        "        self.rotation = rotation\n",
        "        self.horizontal_shift = horizontal_shift\n",
        "        self.vertical_shift = vertical_shift\n",
        "\n",
        "    def rotate(self, a: np.array):\n",
        "        rotated = rotate(a, np.random.normal(scale = self.rotation))\n",
        "        while rotated.shape[0] != 28:\n",
        "            rotated = np.delete(rotated, 0, axis = 0)\n",
        "            if rotated.shape[0] != 28:\n",
        "                rotated = np.delete(rotated, -1, axis = 0)\n",
        "\n",
        "        while rotated.shape[1] != 28:\n",
        "            rotated = np.delete(rotated, 0, axis = 1)\n",
        "            if rotated.shape[1] != 28:\n",
        "                rotated = np.delete(rotated, -1, axis = 1)\n",
        "\n",
        "        return rotated\n",
        "        \n",
        "    def shift_horizontally(self, a: np.array):\n",
        "        return shift(a, (0, np.random.normal(scale = self.horizontal_shift)), output = a)\n",
        "\n",
        "    def shift_vertically(self, a: np.array):\n",
        "        return shift(a, (np.random.normal(scale = self.vertical_shift), 0), output = a)\\\n",
        "\n",
        "    def augment(self, X: np.array, Y: np.array, n: int = 3):\n",
        "        result_X = []\n",
        "        result_Y = [] \n",
        "\n",
        "        for x, y in zip(X, Y):\n",
        "            result_X.append(x)\n",
        "            result_Y.append(y)\n",
        "\n",
        "            for i in range(n):\n",
        "                result_X.append(np.reshape(self.shift_horizontally(self.shift_vertically(self.rotate(np.reshape(x, (28, 28))))), 28*28))\n",
        "                result_Y.append(y)\n",
        "\n",
        "        return np.array(result_X), np.array(result_Y)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3gAyqw4bO1p"
      },
      "source": [
        "def sigmoid(z):\n",
        "    return 1.0/(1.0+np.exp(-z))\n",
        "\n",
        "def sigmoid_prime(z):\n",
        "    # Derivative of the sigmoid\n",
        "    return sigmoid(z)*(1-sigmoid(z))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgEA2XRRbO2X"
      },
      "source": [
        "class Network(object):\n",
        "    def __init__(self, sizes):\n",
        "        # initialize biases and weights with random normal distr.\n",
        "        # weights are indexed by target node first\n",
        "        self.num_layers = len(sizes)\n",
        "        self.sizes = sizes\n",
        "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
        "        self.biases_accumulator = [np.zeros([y, 1]) for y in sizes[1:]]\n",
        "        self.weights = [np.random.randn(y, x) \n",
        "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
        "        self.weights_accumulator = [np.zeros([y, x]) \n",
        "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
        "        \n",
        "    def feedforward(self, a):\n",
        "        # Run the network on a batch\n",
        "        a = a.T\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            a = sigmoid(np.matmul(w, a)+b)\n",
        "        return a\n",
        "    \n",
        "    def update_mini_batch(self, mini_batch, eta, momentum=0, l2=0):\n",
        "        # Update networks weights and biases by applying a single step\n",
        "        # of gradient descent using backpropagation to compute the gradient.\n",
        "        # The gradient is computed for a mini_batch which is as in tensorflow API.\n",
        "        # eta is the learning rate      \n",
        "        nabla_b, nabla_w = self.backprop(mini_batch[0].T,mini_batch[1].T)\n",
        "        \n",
        "        self.weights_accumulator = [momentum*w-(eta/len(mini_batch[0]))*nw \n",
        "                                    for w, nw in zip(self.weights_accumulator, nabla_w)]            \n",
        "        self.weights = [(1.0 - l2)*w + wa for w, wa in zip(self.weights, self.weights_accumulator)]\n",
        "        \n",
        "        self.biases_accumulator = [momentum*b-(eta/len(mini_batch[0]))*nb \n",
        "                       for b, nb in zip(self.biases_accumulator, nabla_b)]\n",
        "        self.biases = [b+ba for b, ba in zip(self.biases, self.biases_accumulator)]\n",
        "        \n",
        "    def backprop(self, x, y):\n",
        "        # For a single input (x,y) return a pair of lists.\n",
        "        # First contains gradients over biases, second over weights.\n",
        "        g = x\n",
        "        gs = [g] # list to store all the gs, layer by layer\n",
        "        fs = [] # list to store all the fs, layer by layer\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            f = np.dot(w, g)+b\n",
        "            fs.append(f)\n",
        "            g = sigmoid(f)\n",
        "            gs.append(g)\n",
        "        # backward pass <- both steps at once\n",
        "        dLdg = self.cost_derivative(gs[-1], y)\n",
        "        dLdfs = []\n",
        "        for w,g in reversed(list(zip(self.weights,gs[1:]))):\n",
        "            dLdf = np.multiply(dLdg,np.multiply(g,1-g))\n",
        "            dLdfs.append(dLdf)\n",
        "            dLdg = np.matmul(w.T, dLdf)\n",
        "        \n",
        "        dLdWs = [np.matmul(dLdf,g.T) for dLdf,g in zip(reversed(dLdfs),gs[:-1])] # automatic here\n",
        "        dLdBs = [np.sum(dLdf,axis=1).reshape(dLdf.shape[0],1) for dLdf in reversed(dLdfs)] # CHANGE: Need to sum here\n",
        "        return (dLdBs,dLdWs)\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "        # Count the number of correct answers for test_data\n",
        "        pred = np.argmax(self.feedforward(test_data[0]),axis=0)\n",
        "        corr = np.argmax(test_data[1],axis=1).T\n",
        "        return np.mean(pred==corr)\n",
        "    \n",
        "    def cost_derivative(self, output_activations, y):\n",
        "        return (output_activations-y) \n",
        "    \n",
        "    def SGD(self, training_data, epochs, mini_batch_size, eta, momentum=0, l2=0, early_stop=None, validation_data=None):\n",
        "        x_train, y_train = training_data\n",
        "        accuracy_val = []\n",
        "        if validation_data:\n",
        "            x_validation, y_validation = validation_data\n",
        "        for j in range(epochs):\n",
        "            for i in range(x_train.shape[0] // mini_batch_size):\n",
        "                x_mini_batch = x_train[(mini_batch_size*i):(mini_batch_size*(i+1))]\n",
        "                y_mini_batch = y_train[(mini_batch_size*i):(mini_batch_size*(i+1))]\n",
        "                self.update_mini_batch((x_mini_batch, y_mini_batch), eta, momentum, l2)\n",
        "            if validation_data:\n",
        "                current_accuracy = self.evaluate((x_validation, y_validation))\n",
        "                print(\"Epoch: {0}, Accuracy: {1}\".format(j, current_accuracy))\n",
        "                accuracy_val.append(current_accuracy)\n",
        "                if early_stop and len(accuracy_val) > early_stop:\n",
        "                    best_accuracy = max(accuracy_val[:-early_stop])\n",
        "                    last_accuracy = max(accuracy_val[-early_stop:])\n",
        "                    if last_accuracy <= best_accuracy:\n",
        "                        print(\"Early stop\")\n",
        "                        break\n",
        "            else:\n",
        "                print(\"Epoch: {0}\".format(j))\n",
        "        return accuracy_val\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_aZY2Ove207"
      },
      "source": [
        "network = Network([784,128,64,10])\n",
        "augmenter = Augmenter()\n",
        "train_data = augmenter.augment(x_train, y_train) "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BApfkylcGhXP",
        "outputId": "907d5da7-8f69-48df-c617-4f9b778a1085"
      },
      "source": [
        "accuracy_val = network.SGD(train_data, epochs=100, mini_batch_size=100, eta=0.03, l2=0.00001,\n",
        "                       momentum=0.9, early_stop=10, validation_data=(x_validation, y_validation))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Accuracy: 0.8053\n",
            "Epoch: 1, Accuracy: 0.8625\n",
            "Epoch: 2, Accuracy: 0.9003\n",
            "Epoch: 3, Accuracy: 0.919\n",
            "Epoch: 4, Accuracy: 0.9311\n",
            "Epoch: 5, Accuracy: 0.9392\n",
            "Epoch: 6, Accuracy: 0.9453\n",
            "Epoch: 7, Accuracy: 0.9494\n",
            "Epoch: 8, Accuracy: 0.9529\n",
            "Epoch: 9, Accuracy: 0.9548\n",
            "Epoch: 10, Accuracy: 0.9565\n",
            "Epoch: 11, Accuracy: 0.9588\n",
            "Epoch: 12, Accuracy: 0.9604\n",
            "Epoch: 13, Accuracy: 0.9609\n",
            "Epoch: 14, Accuracy: 0.9624\n",
            "Epoch: 15, Accuracy: 0.9635\n",
            "Epoch: 16, Accuracy: 0.9637\n",
            "Epoch: 17, Accuracy: 0.964\n",
            "Epoch: 18, Accuracy: 0.9645\n",
            "Epoch: 19, Accuracy: 0.9648\n",
            "Epoch: 20, Accuracy: 0.9653\n",
            "Epoch: 21, Accuracy: 0.9656\n",
            "Epoch: 22, Accuracy: 0.9661\n",
            "Epoch: 23, Accuracy: 0.9665\n",
            "Epoch: 24, Accuracy: 0.9669\n",
            "Epoch: 25, Accuracy: 0.9672\n",
            "Epoch: 26, Accuracy: 0.9679\n",
            "Epoch: 27, Accuracy: 0.9681\n",
            "Epoch: 28, Accuracy: 0.9689\n",
            "Epoch: 29, Accuracy: 0.9691\n",
            "Epoch: 30, Accuracy: 0.9692\n",
            "Epoch: 31, Accuracy: 0.9693\n",
            "Epoch: 32, Accuracy: 0.9694\n",
            "Epoch: 33, Accuracy: 0.9694\n",
            "Epoch: 34, Accuracy: 0.9699\n",
            "Epoch: 35, Accuracy: 0.9705\n",
            "Epoch: 36, Accuracy: 0.9705\n",
            "Epoch: 37, Accuracy: 0.9705\n",
            "Epoch: 38, Accuracy: 0.9708\n",
            "Epoch: 39, Accuracy: 0.9705\n",
            "Epoch: 40, Accuracy: 0.9706\n",
            "Epoch: 41, Accuracy: 0.9707\n",
            "Epoch: 42, Accuracy: 0.9706\n",
            "Epoch: 43, Accuracy: 0.9706\n",
            "Epoch: 44, Accuracy: 0.9708\n",
            "Epoch: 45, Accuracy: 0.9709\n",
            "Epoch: 46, Accuracy: 0.9713\n",
            "Epoch: 47, Accuracy: 0.9715\n",
            "Epoch: 48, Accuracy: 0.9716\n",
            "Epoch: 49, Accuracy: 0.9717\n",
            "Epoch: 50, Accuracy: 0.9715\n",
            "Epoch: 51, Accuracy: 0.9715\n",
            "Epoch: 52, Accuracy: 0.9714\n",
            "Epoch: 53, Accuracy: 0.9715\n",
            "Epoch: 54, Accuracy: 0.9717\n",
            "Epoch: 55, Accuracy: 0.9718\n",
            "Epoch: 56, Accuracy: 0.972\n",
            "Epoch: 57, Accuracy: 0.9722\n",
            "Epoch: 58, Accuracy: 0.9723\n",
            "Epoch: 59, Accuracy: 0.9725\n",
            "Epoch: 60, Accuracy: 0.9726\n",
            "Epoch: 61, Accuracy: 0.9727\n",
            "Epoch: 62, Accuracy: 0.973\n",
            "Epoch: 63, Accuracy: 0.973\n",
            "Epoch: 64, Accuracy: 0.9731\n",
            "Epoch: 65, Accuracy: 0.9731\n",
            "Epoch: 66, Accuracy: 0.9735\n",
            "Epoch: 67, Accuracy: 0.9735\n",
            "Epoch: 68, Accuracy: 0.9737\n",
            "Epoch: 69, Accuracy: 0.9737\n",
            "Epoch: 70, Accuracy: 0.9736\n",
            "Epoch: 71, Accuracy: 0.9736\n",
            "Epoch: 72, Accuracy: 0.9736\n",
            "Epoch: 73, Accuracy: 0.9737\n",
            "Epoch: 74, Accuracy: 0.9738\n",
            "Epoch: 75, Accuracy: 0.9739\n",
            "Epoch: 76, Accuracy: 0.9739\n",
            "Epoch: 77, Accuracy: 0.974\n",
            "Epoch: 78, Accuracy: 0.974\n",
            "Epoch: 79, Accuracy: 0.9741\n",
            "Epoch: 80, Accuracy: 0.9741\n",
            "Epoch: 81, Accuracy: 0.9741\n",
            "Epoch: 82, Accuracy: 0.9741\n",
            "Epoch: 83, Accuracy: 0.9741\n",
            "Epoch: 84, Accuracy: 0.9741\n",
            "Epoch: 85, Accuracy: 0.9743\n",
            "Epoch: 86, Accuracy: 0.9745\n",
            "Epoch: 87, Accuracy: 0.9745\n",
            "Epoch: 88, Accuracy: 0.9744\n",
            "Epoch: 89, Accuracy: 0.9744\n",
            "Epoch: 90, Accuracy: 0.9744\n",
            "Epoch: 91, Accuracy: 0.9743\n",
            "Epoch: 92, Accuracy: 0.9744\n",
            "Epoch: 93, Accuracy: 0.9744\n",
            "Epoch: 94, Accuracy: 0.9743\n",
            "Epoch: 95, Accuracy: 0.9744\n",
            "Epoch: 96, Accuracy: 0.9744\n",
            "Early stop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6CgZafSScca",
        "outputId": "e26ee074-c45d-4ce9-ebb5-b5cb84703775"
      },
      "source": [
        "final_accuracy = network.evaluate((x_test, y_test))\n",
        "print(\"Accuracy on a test set:\", final_accuracy)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on a test set: 0.9763\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}